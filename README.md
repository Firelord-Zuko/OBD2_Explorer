![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Flask](https://img.shields.io/badge/Framework-Flask-green)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![LLM](https://img.shields.io/badge/AI_Model-TinyLlama_1.1B-orange)
![Status](https://img.shields.io/badge/Status-Stable-success)

# ğŸš— OBD-II Explorer Project

### Author
**Sanford Janes Witcher III**  
**Version:** v1.3.9  
**Date:** October 27, 2025  

---

## ğŸ“˜ Overview
**OBD-II Explorer** is a self-hosted, offline-capable AI diagnostic web application that decodes automotive error codes using a local LLM (TinyLlama or Mistral).  
Itâ€™s optimized for **speed, privacy, and offline operation**, providing instant summaries, technical explanations, and DIY repair guidance through a lightweight **Flask** interface.

---

## ğŸ§© Project Structure
```
OBD-II_Explorer/
â”œâ”€â”€ app.py                        # Main Flask application logic
â”œâ”€â”€ Dockerfile                    # Container build instructions
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # Project documentation
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ obd2_codes.db             # SQLite database of OBD-II codes
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf   # Local lightweight model
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ styles.css                # Application styles
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                # Web front-end
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ build.ps1                 # Docker build script
    â”œâ”€â”€ rebuild.ps1               # Rebuild + clean options
    â”œâ”€â”€ start_container.ps1       # Start container
    â””â”€â”€ stop_container.ps1        # Stop container
```

---

## âš™ï¸ Configuration

### Environment Variables
| Variable | Default | Description |
|-----------|----------|-------------|
| `DB_PATH` | `/app/data/obd2_codes.db` | Path to SQLite database |
| `MODEL_PATH` | `/app/models/tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf` | Path to local model |
| `CACHE_PATH` | `/app/cache` | Disk cache for AI results |

---

## ğŸ§  Release Highlights (v1.3.9)

### ğŸ§© Backend (Flask)
- Maintains database integrity and ensures schema validation  
- Returns AI last-updated timestamps and code source  
- Supports local model inference (TinyLlama / Mistral via llama.cpp)

---

### ğŸ¨ Front-End (index.html + styles.css)
| Feature | Description |
|----------|-------------|
| ğŸ” **Code Normalization** | Automatically fixes user input (e.g., `23 â†’ P0023`) |
| ğŸ’¡ **Smart Suggestions** | â€œDid you mean P0123?â€ prompt for invalid input |
| â±ï¸ **Timestamp Tracking** | Displays â€œLast Checkedâ€ date/time for each lookup |
| ğŸ§­ **Local Quick Cache** | Instant results on repeat lookups â€” even offline |
| ğŸŒ™ **Light/Dark Mode** | Smooth transitions, persistent preference |
| ğŸ§° **DIY Recommendations** | Expanded multi-line list with collapsible tips |
| ğŸ—‘ï¸ **Smart Clear Button** | Clears history + input field with fade animation |
| âš¡ **Offline Resilience** | Cached data served instantly if backend unreachable |
| ğŸ“œ **Icons Restored** | Visual section markers (ğŸ“œ, ğŸ“˜, ğŸ§°, ğŸ”—, ğŸ•˜) |
| ğŸ§  **Auto-Focus & Select** | Focuses input box after lookup for fast re-entry |
| ğŸ“± **Responsive Design** | Mobile-first layout with compact toolbar |

---

## ğŸ§® Local Cache Logic
OBD-II Explorer now includes an intelligent caching layer:

| Function | Behavior |
|-----------|-----------|
| **setCache()** | Stores code result JSON in `localStorage` |
| **getCache()** | Loads cached results if available |
| **fromCache** | Displays â€œâš¡ Loaded from Local Cacheâ€ for reused codes |
| **clear** | Removes cache + history from localStorage |

This reduces lookup latency to 0ms for previously searched codes and allows fully offline use once results have been cached.

---

## ğŸ§± Docker Setup

### Build Image
```bash
docker build -t obd2_explorer .
```

### Run Container
```bash
docker run -d -p 8888:8888 \
  --name obd2_explorer \
  -v "${PWD}/models:/app/models" \
  -v "${PWD}/data:/app/data" \
  obd2_explorer
```

Access the web app at:  
ğŸ”— **http://localhost:8888**

---

## ğŸ’¾ Requirements
- **Python 3.10+**
- **Flask**
- **Docker Desktop** (Windows/Linux)
- **8GB RAM minimum** for LLM inference  
- **Browser with localStorage support**

---

## ğŸ§¡ Credits
- **Author:** Sanford Janes Witcher III  
- **Model:** TinyLlama 1.1B Chat (GGUF)  
- **Backend:** Flask + Gunicorn + llama.cpp  
- **Database:** SQLite3  
- **Frontend:** Bootstrap 5 + Vanilla JS  

---

## ğŸ§­ Version History
| Version | Date | Notes |
|----------|------|-------|
| **v1.3.9** | Oct 28, 2025 | Local Quick Cache, offline-ready, smart validation |
| **v1.3.8** | Oct 28, 2025 | Added timestamps, improved dark mode visibility |
| **v1.3.7** | Oct 27, 2025 | Tier 1 UX: narrower input, smoother transitions |
| **v1.3.6** | Oct 27, 2025 | Fixed regex bug + added Clear button UX fade |
| **v1.3.5** | Oct 27, 2025 | Restored icons, input clear logic, dark toggle fix |
| **v1.3.4** | Oct 27, 2025 | Spinner & gradient fix |
| **v1.3.3** | Oct 27, 2025 | Toolbar repositioned + dark toggle cleanup |
| **v1.3.2** | Oct 26, 2025 | Style refinement, centered toolbar |
| **v1.3.1** | Oct 25, 2025 | Input normalization logic added |
| **v1.3.0** | Oct 24, 2025 | Base stable release |

---

## ğŸ·ï¸ License
This project is licensed under the **MIT License** â€” free for personal and commercial use with attribution.

---

## ğŸ—•ï¸ Last Updated
**October 27, 2025**
